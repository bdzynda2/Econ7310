---
title: 'ECN 7310 Project #2'
author: "David Zynda"
date: "November 22, 2017"
output: pdf_document
---

```{r setup, include=FALSE, fig.align='center'}
knitr::opts_chunk$set(echo = TRUE)
```


# Introduction

This Project will seek to highlight and further examine some of the work being done on research concerning the economic impact of Renewable Portfolio Standards implemented at the state level. Five economic variables were originally selected to be fit in a VAR-X model, or a multivariate time series model with an exogenous variable(s). Recent adaptations of the model, whose work is the creation of Dr. Tyler Brough, limited the VAR-X to three variables to improve the overall degrees of freedom. With 3 lags, the model would need 125 parameter (25 variables per lag) estimates for roughly 200 observations assuming all variables were used. Additionally, the effect of cointegration may be present if all variables are used. Therefore, of the five variables including average weekly hours worked in manufacturing, nonfarm employment, unemployment rate, total personal income minus transfer payments, and industrial electricity sales, only the latter three were used in the most recent analysis. 

The goal of this project will be to further explore the potential presence and effect of cointegrating relationships with the inclusion of one of the omitted variables. For the sake of simplicity, the eventual VAR and VECM will be fit with three variables. I will choose ones that have the highest degree of cointegrating relationships. Then, I will fit these variables to both a VAR and a VECM to see how much the inclusion of the error correction component makes. Such exploration is important because our own Bayesian Vector Autoregression incorporates no error correction, even in wake of some potential cointegrating relationships among the three variables listed above which the model includes. Omitting the cointegrating term when a series is cointegrated could result in large model misspecification. 

# Data 

Following the example of the Federal Reserve Bank of Philadelphia[^1] in measuring the strength of a regional economy, this project employs seasonally adjusted monthly state unemployment rates, monthly industrial electricity sales, and quarterly state personal income minus transfer payments beginning in January of 2001 and ending on April 2017 for the state of Ohio. 

Industrial Electricity Sales are used as a measure of a state's industrial production and activity. These sales numbers are reported in millions of kilowatthours by the US Department of Energy. These data were obtained from the US Energy Information Administration. Unemployment data for each state was collected from the Bureau of Labor Statistics, as was average weekly hours worked in Manufacturing, and nonfarm employment in thousands of persons. Lastly, quarterly state personal income and transfer payments were gathered from the Bureau of Economic Analysis and reported in thousands of dollars.

Because state personal income is reported quarterly rather than monthly, cubic spline interpolation was used to estimate monthly points between each quarter after subtracting out transfer payments from the total state income. A common practice used in econometrics, spline interpolation does not generate new data points but rather estimates data between observed data points. The interpolated data and the observed data on state personal income were not adjusted for inflation. Using the consumer price index available from the Bureau of Labor Statistics, the income data were set to September 2017 US Dollars.


# Methods

I will test for the presence of cointegration according to the method of Engle-Granger[^1]. This is done by first testing each series for the presence of a unit root using the Augmented Dickey Fuller Test and the Zivot Andrews Test. If they are integrated of order 1, or stationary after differencing once, the series are regressed on each other using ordinary least squares estimates. The residuals from this model are then tested for stationarity. If stationary, then the series are cointegrated. 

Models will be fit using the R package `vars` and `tsDyn`. This package will fit a VAR and VECM model using ordinary least squares and maximum likelihood estimation. In order to conserve degrees of freedom, I will assume a lag length of 2 for both models. Using the paramter estimates, I will perform a simulation to see how closely the estimated VAR and VECM fit the original path of the data. 

Lastly, in addition to the aforementioned variables, a dummy variable represent the Great Recession beginning on December 2007 and ending on June 2009 will be included to account for the great shock occuring in the data during that time. Additionally an RPS dummy variable set to 1 when a standard is enacted will also be included. 

```{r, echo=FALSE, results='hide'}
library(urca)
library(moments)
library(vars)
library(tsDyn)

exog <- read.csv("OH_exog.csv", header = FALSE)
# rec.ts <- ts(exog$V2, start = 2001, frequency = 12)
# rps.ts <- ts(exog$V1, start = 2001, frequency = 12)
rec <- exog$V2
rps <- exog$V1

manhours <- read.csv("AvgManHours_Ohio.csv", header = TRUE)
manHours <- manhours$SMU39000003000000007SA

nonFarm <- read.csv("Nonfarm_Ohio.csv", header = TRUE)
nonfarm <- nonFarm$OHNA

ohio <- read.csv("Ohio_formatted.csv", header = TRUE)
colnames(ohio) <- c("elect", "income", "unemp")
attach(ohio)

manHours.ts <- ts(manHours, start = 2001, frequency = 12)
nonfarm.ts <- ts(nonfarm, start = 2001, frequency = 12)
elect.ts <- ts(elect, start = 2001, frequency = 12)
income.ts <- ts(income, start = 2001, frequency = 12)
unemp.ts <- ts(unemp, start = 2001, frequency = 12)
```

## Augmented Dickey-Fuller Test

First stationarity is examined among the variables using the ADF Test. 


The Augmented Dickey Fuller Test specifies as a null hypothesis that a time series is a unit root process. In other words, a the null hypothesis assumes the series is not stationary. Let:

$$ \Delta y_t = \beta_1 + \beta_2t + \pi y_{t-1} + \sum_{j=1}^k \gamma_j \Delta y_{t-j} + u_i  $$

where $\beta_1$ is a drift term, $\beta_2$ is a trend, and $\rho = 1$ is the unit root and $\pi = \rho - 1$. Hence, the null hypothesis is specified as $H_0: \pi = 0$ and therefore unit root $\rho = 1$. However, applying the ADF test to a series that is possibly trend stationary may not reject $H_0$ and consequently not reject the presence of a unit root. For this reason, other test statistics need to be examined to ensure whether or not $\beta_1 = 0$ and $\beta_2 = 0$. Using the regression result from the equation above, the following test statistics will be evaluated for significance:

$$ \tau_3: \pi = 0 $$
$$ \phi_3: \pi = \beta_2 = 0 $$
$$ \phi_2: \pi = \beta_1 = \beta_2 = 0$$
A similar process will be conducted for the following regressions to ensure no presence of trend or drift:

$$ \Delta y_t = \beta_1  + \pi y_{t-1} + \sum_{j=1}^k \gamma_j \Delta y_{t-j} + u_i  $$
with

$$ \tau_2: \pi = 0 $$
$$ \phi_1 : \pi = \beta_1 = 0 $$

and 

$$ \Delta y_t =  \pi y_{t-1} + \sum_{j=1}^k \gamma_j \Delta y_{t-j} + u_i  $$
with
$$ \tau_1 : \pi = 0 $$

Rejecting any one of the $\phi$ null hypotheses implies that at least one term is not equal to zero. One must begin with assuming both trend and drift are present and work down from there. A rejection of $\tau$ at any level implies that the series does not have a unit root. 

### Sample Code implementing ADF Test for Average Manufacturing Hours

```{r}
summary(ur.df(manHours.ts, type = 'trend', lags = 3))
summary(ur.df(manHours.ts, type = 'drift', lags = 3))
summary(ur.df(manHours.ts, type = 'none', lags = 3))
```
$\newline$

As can be seen in every case, the unit root null hypothesis cannot be rejected. Furthermore, there is no presence of drift nor trend. The results of the other variables can be seen below. 

### Table 1: Results of the Augmented Dickey Fuller Test on the Ohio Data

|Variable                   |ADF result                 |
|:--------------------------|:-------------------------:|
|Avg. Manufacturing Hours   |Unit Root Present          |
|Nonfarm Employment         |Unit Root Present          |
|Industrial Electriciy Sales|Stationary                 |
|Total Income               |Unit Root Present          |
|Unemployment Rate          |Unit Root Present          |


Where there is a unit root present, log first differencing is used to check and see if the process is integrated of order 1, $I(1)$. 

### Sample Code with Log First Differencing on Average Manufacturing Hours

```{r}
manHours.ln <- diff(log(manHours.ts))
summary(ur.df(manHours.ln, type = 'trend', lags = 3))
```
$\newline$

|Variable                   |Log First Difference ADF   |
|:--------------------------|:-------------------------:|
|Avg. Manufacturing Hours   |Stationary                 |
|Nonfarm Employment         |Unit Root Present          |
|Total Income               |Stationary                 |
|Unemployment Rate          |Stationary                 |

Nonfarm Employment may be $I(2)$ or perhaps of a higher order of integration. For sake of simplicity and demonstration, we will continue without it as mentioned before. However, all other variables are $I(1)$. 


## Zivot-Andrews Test

Failing to account for structural breaks may threaten the result, be it a rejection or failure of rejection of a null, gathered from the Augmented Dickey-Fuller. Because this data encapsulates the Great Recession, it may make sense to consider another test which takes into account the presence of a structural break. The Zivot-Andrews Test examines the presence of a unit root in a time series with a structural break by endogenously determining a potential break. This is done by selecting the break at the point in the series that minimizes the t-statistic which gives the greatest evidence against the null hypothesis. The Zivot-Andrews test, upon rejecting a null hypothesis of a unit root, allows for one to conclude that a time series process may be stationary with one break in trend or intercept. 

As with Dickey-Fuller, $H_0$ entails that a unit root is present.

In the output below, `du` is the coefficient of a dummy variable that allows for a one time shift in the levels of the series. Also, `dt` respresents the coefficient of a dummy variable that allows for change in rate of growth. 

The test will be run with both a potential break in intercept as well as trend to account for any form by which the recession may have effected the data. 


### Sample Code and Plots for Zivot-Andrews Test Using Unemployment

$\newline$
```{r}
unemp.za <- ur.za(unemp.ts, model = 'both', lag = 3)
summary(unemp.za)
plot(unemp.za)
```
$\newline$

```{r, echo = FALSE}
plot.ts(unemp.ts*100, 
        main = "Ohio Unemployment Rate with Recession",
        xlab = 'Year',
        ylab = 'Unemployment Rate',
        xaxt = 'n')
axis(side = 1, at = seq.int(2001, 2017, 2))
recStart <- 2007 + 11/12
recEnd <- 2009 + 5/12
rect(xleft = recStart, xright = recEnd, ybottom=par("usr")[3], ytop=par("usr")[4], density=10, col = "blue")
```

In this instance of the Zivot-Andrews Test testing the unemployment variable, it can be seen that there is a suggested break point at position 93 which corresponds to the date of September 2008 in the middle of the Great Recession. Thereore, it can be concluded that this series is stationary with either a break in trend or intercept or both. 



### Sample Code for the Zivot-Andrews Test Using Average Hours Worked in Manufacturing

$\newline$

```{r}
manHours.za <- ur.za(manHours.ts, model = 'both', lag = 3)
summary(manHours.za)
plot(manHours.za)

```

$\newline$

In contrast, it can be seen that average hours worked in manufacturing does not reject the unit root hypothesis, despite the presence of a potential break. For this process, it can be concluded that a unit root is present, consistent with the Augmented Dickey Fuller results above. 


$\newline$


|Variable                   |Zivot Andrews Results      |
|:--------------------------|:-------------------------:|
|Avg. Manufacturing Hours   |Unit Root Present          |
|Nonfarm Employment         |Stationary                 |
|Total Income               |Unit Root Present          |
|Unemployment Rate          |Stationary                 |

$\newline$

In theory, there is no need to test the first differences of the processes using the Zivot-Andrews test because any big changes will be taken care of through differencing. The results of the ADF Test should suffice. 


## Cointegration

Given that the series are integrated of order 1, we proceed to test for any cointegrated relationships. This is done using the method of Engle-Granger[^3]. 

Given 2 different $I(1)$ time series: 

$$ y_t = \alpha_0 + \beta_y y_{t-1} + \epsilon_t  $$

$$x_t = \alpha_1 + \beta_x x_{t-1} + \nu_t $$


Let: 

$$y_t = \beta_0 + \gamma_1 x_t + z_t$$

be the linear combination of the time series. Through linear regression, the residuals $z_t$ can be generated. If this new series $z_t = \gamma_0 y_t - \gamma_1 x_t$ is $I(0)$, then there exits a cointegrated relationship.

Cointegration is eveident visually by observing two or more series following a similar long term trend. This can be seen in the plot below with income and manufacturing hours. They follow the same path with the exception of short term deviations. Error correction components essentially act as the tie between two series such that no one series deviates far from the other. 

Here, income and manufacturing hours will be tested for a cointegrating relationship since they are both $I(1)$ according to the ADF Test and the Zivot-Andrews Test, along with visual evidence of cointegration. 


### Plots
```{r, echo = FALSE}

plot.ts(cbind(income.ts, manHours.ts, unemp.ts), main='RPS Variables',
     xy.labels=FALSE)

```
$\newline$

## Sample Code regressing average hours worked in manufacturing with income 

```{r}

coint.lm <- lm(income.ts ~ manHours.ts)
summary(coint.lm)

plot(coint.lm$residuals, type='l', ylab = 'Residuals')
qqnorm(coint.lm$residuals)
qqline(coint.lm$residuals)


skew <- skewness(coint.lm$residuals)
kurt <- kurtosis(coint.lm$residuals)

```

$\newline$

Overall, the residuals seem to follow rougly stationary trend according to the plot above. The Normal QQ Plot shows a bit of a flattening towards the middle and is concave up, indicating a positive skew. In fact, the exact amount of skewness and kurtosis is `r skew` and `r kurt` respectively. As such, the skewness is rather low, but the kurtosis may be a little high due to the outliers found at the end of the upper tail on the QQ plot. This can be attributed in the residual time seris plot to what appears to be a change in regime towards the end of the series. Overall, this data looks okay to complete reliable further analysis.

Implementing the Augmented Dickey Fuller Test yields the following result:


$\newline$


```{r}
coint.df <- ur.df(coint.lm$residuals, type = 'none', selectlags = 'AIC')
summary(coint.df)

```

$\newline$

The test statistic is very significant and the unit root null hypothesis is rejected in favor of stationarity. It is concluded that the residuals of the linear combination of the two series constituting average hours worked in manufacturing and income is stationary and thus the series are cointegrated. 


## Model Fitting

Now that it is certain that two of the three variables are cointegrated, I will compare the model fitting of these variables in a vector autoregressive model and a vector error correction model. 

### VAR Model



```{r}

series <- cbind(income.ts, manHours.ts, unemp.ts)
series <- ts(series, start = 2001, frequency = 12)


model.var <- VAR(series, p = 2, type = 'both', exogen = cbind(rec, rps))
summary(model.var)


```
$\newline$

The fitted model with significant terms can be represented as follows. The variables $i$, $h$, and $u$ represent income, average weekly hours worked in manufacturing and unemployment rate respectively. 



$$ 
\begin{bmatrix}
i_t \\
h_t \\
u_t
\end{bmatrix}
=
\begin{bmatrix}
1.44 & 0 & -2.28 \\
0  &  0.479  &  -65.78 \\
0  &  0  &  1.64
\end{bmatrix}
\begin{bmatrix}
i_{t-1}  \\
h_{t-1}  \\
u_{t-1} 
\end{bmatrix}
+ 
\begin{bmatrix}
-0.571 & 0 & 0 \\
0  &  0.169  &  0 \\
0  &  0  &  -0.661
\end{bmatrix}
\begin{bmatrix}
i_{t-2}  \\
h_{t-2}  \\
u_{t-2}  
\end{bmatrix}
+
\begin{bmatrix}
-.009374 \\
-.399583 \\
-.0008522
\end{bmatrix}
\gamma
$$

$$
+
\begin{bmatrix}
0 \\
0\\
.000874
\end{bmatrix}
\nu
+
\begin{bmatrix}
0.594  \\
15.12  \\
0  
\end{bmatrix}
+
t
\begin{bmatrix}
0.00027 \\
0  \\
0  
\end{bmatrix}
+
\begin{bmatrix}
\epsilon_1  \\
\epsilon_2  \\
\epsilon_3 
\end{bmatrix}
$$
$\newline$

where $\gamma$ represents the exogenous recession variable and $\nu$ signifies the enactment of a RPS.

$\newline$


### VECM Model


```{r}
model.vecm <- VECM(series, lag=2, r=1, include = 'both', estim = '2OLS', exogen = cbind(rec, rps))
summary(model.vecm)
```
$\pagebreak$

$\newline$
The VECM can be represented as follows.

$\newline$

$$
\begin{bmatrix}
i_t \\
h_t \\
u_t 
\end{bmatrix}
=
\begin{bmatrix}
0.737 & 0 & -4.46 \\
0  &  -.287  &  0 \\
0  &  0  &  0.633
\end{bmatrix}
\begin{bmatrix}
i_{t-1}  \\
h_{t-1}  \\
u_{t-1}  
\end{bmatrix}
+ 
\begin{bmatrix}
-.359 & -.0044 & 2.63 \\
0  &  0  &  0 \\
0  &  0  &  0
\end{bmatrix}
\begin{bmatrix}
i_{t-2}  \\
h_{t-2}  \\
u_{t-2}  
\end{bmatrix}
+
\begin{bmatrix}
0 \\
-.2524 \\
.0007
\end{bmatrix}
\gamma
$$

$$
+
\begin{bmatrix}
0 \\
0 \\
0 
\end{bmatrix}
\nu
+
\begin{bmatrix}
-.0401\\
2.0273  \\
0  
\end{bmatrix}
\begin{bmatrix}
z_{i,t}  \\
z_{h,t}  \\
z_{u,t}  
\end{bmatrix}
+
\begin{bmatrix}
0  \\
0.291  \\
0  
\end{bmatrix}
+
\newline
t
\begin{bmatrix}
0  \\
-.0035  \\
0  
\end{bmatrix}
+
\begin{bmatrix}
\varepsilon_1  \\
\varepsilon_2  \\
\varepsilon_3 
\end{bmatrix}
$$

$\newline$

where $\gamma$ represents the exogenous recession variable and $\nu$ signifies the enactment of a RPS. Each $z$ represents the residuals from the linear combination of all three variables




# Simulations

VAR
```{r}

# series <- data.frame(income.ts, manHours.ts, unemp.ts)
# 
# A1 = matrix(c(1.449, 0, -3.27,
#              0, .5264, -109.5,
#              0,  0,  0), nrow = 3, ncol = 3)
# 
# A2 = matrix(c(-.5616, 0, -2.568,
#              0, .1772, 106.2,
#              0,  0,  -.7768), nrow = 3, ncol = 3)
# 
# dvar = matrix(c(.4494, 8.521, 0.2185), nrow = 3, ncol = 1)
# tvar = matrix(c(.0001834, 0, 0), nrow = 3, ncol = 1)

# t = c(1:nrow(series))
# 
# e1 = rnorm(nrow(series))
# e2 = rnorm(nrow(series))
# e3 = rnorm(nrow(series))
# 
# e = data.frame(e1,e2,e3)
# 
# i = rep(0, nrow(series)); i[1:2] = income.ts[1:2]
# h = rep(0, nrow(series)); h[1:2] = manHours.ts[1:2]
# u = rep(0, nrow(series)); u[1:2] = unemp.ts[1:2]
# 
# for(j in (1:191)){
#   i[j+2] = 1.449*i[j+1]  -  3.27*u[j+1]  -  .5616*i[j]  +  2.568*u[j]  +  .4494  +  t*.0001834 + e1
#   h[j+2] = .5264*h[j+1]  -  109.5*u[j+1]  +  .1772*h[j]  +  106.2*u[j]  +  8.521 + e2
#   u[j+2] = 1.746*u[j+1]  -  .7768*u[j]  +  .02185 + e3
# }


```









[^1]: https://www.philadelphiafed.org/-/media/research-and-data/publications/business-review/2000/november-december/brnd00tc.pdf?la=en
[^2]: Robert F. Engle and CWJ Granger, "Co-Integration and Error Correction: Representation, Estimation, and Testing", Econometrica, vol. 55, no. 2, March 1987, pp. 251-276.
[^3]: _Ibid._



























